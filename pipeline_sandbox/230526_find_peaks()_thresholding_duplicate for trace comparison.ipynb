{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports from Marti Utility scripts\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.markers as markers\n",
    "import scipy.signal as signal\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "from BaselineRemoval import BaselineRemoval\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_min(input_series, window_size):\n",
    "    r = input_series.rolling(window_size, min_periods=1)\n",
    "    m = r.min()\n",
    "    return m\n",
    "\n",
    "\n",
    "def remove_bleaching(input_trace):\n",
    "    min_trace = rolling_min(pd.Series(input_trace), window_size=int(len(input_trace)/10))\n",
    "    fit_coefficients = np.polyfit(range(len(min_trace)), min_trace, 2)\n",
    "    fit = np.poly1d(fit_coefficients)\n",
    "    return input_trace - fit(range(len(input_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.markers as markers\n",
    "import scipy.signal as signal\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "from BaselineRemoval import BaselineRemoval\n",
    "import os\n",
    "def load(fp):\n",
    "    stat = np.load(f\"{fp}\\stat.npy\", allow_pickle = True)\n",
    "    ops = np.load(f\"{fp}\\ops.npy\", allow_pickle = True).item()\n",
    "    F = np.load(f\"{fp}\\F.npy\", allow_pickle = True)\n",
    "    Fneu = np.load(f\"{fp}\\Fneu.npy\", allow_pickle = True)\n",
    "    #iscell / spks also can be repeated in this way\n",
    "    return stat, ops, F, Fneu\n",
    "    \n",
    "stat, ops, F, Fneu = load(r'E:\\001 - Synapse Calcium Imaging\\230727_AMPA_blocker_tests_AAV1_syn_GCaMP6\\cs2\\wtRt_225k_.0.5ul_hSyn_DIV21_100%_25ms_r001_cs1\\suite2p\\plane0')\n",
    "\n",
    "f = F[2]\n",
    "fneu = Fneu[2]\n",
    "\n",
    "def single_spine_peak_plotting(input_f, input_fneu):\n",
    "    i=0\n",
    "    corrected = input_f - (0.7*input_fneu)\n",
    "        # a standard subtraction of fluorescence background immediately surrounding each ROI\n",
    "    corrected_sample_trace = BaselineRemoval(corrected)\n",
    "    corrected_trace = corrected_sample_trace.ZhangFit(repitition=100)\n",
    "        # an adaptively weighted iterated modified polynomial fit that ignores peaks and corrects baseline to 0\n",
    "    peaks, _ = find_peaks(corrected_trace, height = 3*(abs(np.median(corrected_trace)) + abs(corrected_trace.min())), distance = 20)\n",
    "    amplitudes = corrected_trace[peaks] - np.median(corrected_trace)\n",
    "\n",
    "    negative_points = np.where((corrected_trace < np.median(corrected_trace)))[0]\n",
    "# print(negative_points)\n",
    "    decay_points = []\n",
    "    decay_time = []\n",
    "\n",
    "    for i in peaks:\n",
    "        negative_after_peak = negative_points[negative_points>i]\n",
    "        if len(negative_after_peak > 0):\n",
    "            decay_points.append(negative_after_peak[0])\n",
    "\n",
    "    for k,a in zip(peaks, decay_points):\n",
    "        decay_time.append(np.abs(a-k)/20)\n",
    "\n",
    "        # scipy find_peaks function\n",
    "        #then plot the traces you generate\n",
    "    plt.plot(corrected_trace)\n",
    "    plt.plot(peaks, corrected_trace[peaks], \"x\")\n",
    "    plt.plot(np.full_like(corrected_trace, 3*(abs(np.median(corrected_trace)) + abs(corrected_trace.min()))), \"--\",color = \"grey\")\n",
    "    plt.plot(np.full_like(corrected_trace, np.median(corrected_trace)), \"--\", color = 'r')\n",
    "    plt.plot(np.full_like(decay_points, corrected_trace[decay_points], \"d\"))\n",
    "    print('the peak time stamps are :{}' .format(peaks))\n",
    "    print('the peak returns to baseline at frame: {}' .format(decay_points))\n",
    "    print('the decay time in seconds for each peak is: {}' .format(decay_time))\n",
    "    print('the amplitude of each peak is: {}' .format(amplitudes))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def single_synapse_baseline_correction_and_peak_return(input_f, input_fneu, return_peaks = False, return_decay_times = False, return_amplitudes = False):\n",
    "    \n",
    "    corrected_trace = input_f - (0.7*input_fneu)\n",
    "    corrected_trace = BaselineRemoval(corrected_trace)\n",
    "    corrected_trace = corrected_trace.ZhangFit(repitition = 100)\n",
    "    peaks, _ = find_peaks(corrected_trace, height = 3*(abs(np.median(corrected_trace)) + abs(corrected_trace.min())), distance = 40)\n",
    "    amplitudes = corrected_trace[peaks] - np.median(corrected_trace)\n",
    "    negative_points = np.where((corrected_trace < np.median(corrected_trace)))[0]\n",
    "    decay_points = []\n",
    "    decay_time = []\n",
    "\n",
    "    for i in peaks:\n",
    "        negative_after_peak = negative_points[negative_points>i]\n",
    "        if len(negative_after_peak > 0):\n",
    "            decay_points.append(negative_after_peak[0])\n",
    "\n",
    "    next_peak_index = []\n",
    "    for k,a in zip(peaks, decay_points):\n",
    "        if next_peak_index < a:\n",
    "            decay_time.append(np.nan)\n",
    "        \n",
    "        else:\n",
    "            decay_time.append(np.abs(a-k)/20)\n",
    "        \n",
    "        \n",
    "    if return_peaks == True:\n",
    "        return peaks\n",
    "    if return_decay_times == True:\n",
    "        return decay_points\n",
    "    if return_amplitudes == True:\n",
    "        return amplitudes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_test = []\n",
    "amp_test = []\n",
    "decay_test = []\n",
    "n=0\n",
    "for i,j in zip(F, Fneu):\n",
    "    # peak_test.append(single_synapse_baseline_correction_and_peak_return(i,j, return_peaks=True))\n",
    "    # amp_test.append(single_synapse_baseline_correction_and_peak_return(i,j, return_peaks=False, return_amplitudes=True))\n",
    "    # decay_test.append(single_synapse_baseline_correction_and_peak_return(i,j, return_peaks=False, return_decay_times=True))\n",
    "    print(n)\n",
    "    n+=1\n",
    "    single_spine_peak_plotting(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decay_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(peak_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decayed_library = []\n",
    "for f, fneu in zip(F,Fneu):\n",
    "    decayed_library.append(single_synapse_baseline_correction_and_peak_return(f, fneu, return_peaks = False, return_decay_times = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_key = \"lam\"\n",
    "low_std = []\n",
    "for element in stat:\n",
    "    if desired_key in element:\n",
    "        low_std.append(element[desired_key])\n",
    "\n",
    "np.mean(stat[601]['lam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decayed_library\n",
    "second_times = []\n",
    "for i in decayed_library:\n",
    "    second_times.append(i/10)\n",
    "print(second_times) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gives out the time course of each peak (currently threshold is set to 1.5x the noise)\n",
    "\n",
    "f = F[2]\n",
    "fneu = Fneu[2]\n",
    "sample_trace = f - 0.7*fneu\n",
    "corrected_sample_trace = BaselineRemoval(sample_trace)\n",
    "corrected_trace = corrected_sample_trace.ZhangFit(lambda_=500)\n",
    "threshold = 1.5*(abs(np.median(corrected_trace)) + abs(corrected_trace.min()))\n",
    "baseline = np.median(corrected_trace)\n",
    "# print(threshold)\n",
    "\n",
    "peaks, _ = find_peaks(corrected_trace, height = 3*(abs(np.median(corrected_trace)) + abs(corrected_trace.min())), distance = 20)\n",
    "negative_points = np.where((corrected_trace < np.median(corrected_trace)))[0]\n",
    "# print(negative_points)\n",
    "decay_points = []\n",
    "decay_time = []\n",
    "\n",
    "for i in peaks:\n",
    "    negative_after_peak = negative_points[negative_points>i]\n",
    "    if len(negative_after_peak > 0):\n",
    "        decay_points.append(negative_after_peak[0])\n",
    "\n",
    "next_peak_index =  []\n",
    "for k,a in zip(peaks, decay_points):\n",
    "    if len(peaks) > 1:\n",
    "        next_peak_index = peaks[peaks > k].min()\n",
    "        if next_peak_index < a:\n",
    "            decay_time.append(np.nan)\n",
    "        else:\n",
    "            decay_time.append(np.abs(a-k) / 20)\n",
    "    else:\n",
    "        decay_time.append(np.abs(a-k)/20)\n",
    "\n",
    "print(peaks)  \n",
    "print('the peak returns to baseline at frame: {}' .format(decay_points))\n",
    "print('the decay time for each peak is: {}' .format(decay_time))\n",
    "# for i in peaks:\n",
    "#     potential_time_points = np.where((corrected_trace < baseline))\n",
    "#     indices = np.where(potential_time_points > peaks)\n",
    "#     # if len(indices) > 0:\n",
    "#         # peak_index = np.abs(indices - i).argmin()\n",
    "#         # peak_indexes.append(indices[peak_index])\n",
    "#     print(\"Peak index:\", i, \"Index where value equals threshold:\", indices[peak_index])\n",
    "\n",
    "len(decay_points) == len(peaks)\n",
    "\n",
    "\n",
    "\"\"\"Write a code that goes through each of the peaks and decay times; as we add the decay frames to the peak, if there is a second / third peak before the decay time; we change the decay to NaN\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = []\n",
    "for x, y in zip(peaks, decay_points[:]):\n",
    "    if x[0] < y[1]:\n",
    "        print(True)\n",
    "    else:\n",
    "        break            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decay_time = []\n",
    "next_peak =  []\n",
    "start = 0\n",
    "for k,a in zip(peaks, decay_points):\n",
    "    if len(peaks) > 1:\n",
    "        next_peak = peaks[start + 1]\n",
    "        if next_peak < a:\n",
    "            decay_time.append(np.nan)\n",
    "        else:\n",
    "            decay_time.append(np.abs(a-k) / 20)\n",
    "    else:\n",
    "        decay_time.append(np.abs(a-k)/20)\n",
    "    start+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final plotting of the output for testing\n",
    "plt.figure(figsize=(36,6))\n",
    "plt.plot(corrected_trace)\n",
    "plt.plot(np.full_like(corrected_trace, threshold))\n",
    "plt.plot(peaks, corrected_trace[peaks], \"x\")\n",
    "plt.plot(np.full_like(corrected_trace, 3*(abs(np.median(corrected_trace)) + abs(corrected_trace.min()))), \"--\",color = \"grey\")\n",
    "plt.plot(np.full_like(corrected_trace, np.median(corrected_trace)), \"-\",color = \"red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In theory how you remove the values that we set to zero in the initial pass (should \n",
    "#directly lead to a larger std dev of the data)\n",
    "\n",
    "def first_pass_peak_removal():\n",
    "    first_pass = np.copy(corrected_trace)\n",
    "    first_pass_peaks, _ = find_peaks(first_pass, height=0.15*first_pass.max(), distance=5)\n",
    "    peak_regions = []\n",
    "    for peak in first_pass_peaks:\n",
    "        start = max(0, peak-frames)\n",
    "        end = min(len(first_pass)-1, peak+frames+1)\n",
    "        peak_regions += list(np.arange(start, end))\n",
    "    first_pass[peak_regions] = 0\n",
    "    threshold = 3*np.std(first_pass)\n",
    "    first_pass = np.delete(first_pass, peak_regions) # remove values corresponding to peak_regions\n",
    "    return threshold, first_pass\n",
    "\n",
    "threshold, first_pass = first_pass_peak_removal()\n",
    "synapse_peaks, _ = find_peaks(first_pass, height=threshold, distance=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fp):\n",
    "    stat = np.load(f\"{fp}\\stat.npy\", allow_pickle = True)\n",
    "    ops = np.load(f\"{fp}\\ops.npy\", allow_pickle = True).item()\n",
    "    F = np.load(f\"{fp}\\F.npy\", allow_pickle = True)\n",
    "    Fneu = np.load(f\"{fp}\\Fneu.npy\", allow_pickle = True)\n",
    "    #iscell / spks also can be repeated in this way\n",
    "    return stat, ops, F, Fneu\n",
    "\n",
    "stat, ops, F, Fneu = load(r'E:\\230510_homeostatic_plasticity\\49%exp\\TTX\\wtRt_DIV20_AAV1_0.1ul_GCaMP_hSyn_48h_TTX_well001_r001\\suite2p\\plane0')\n",
    "\n",
    "f = F[7]\n",
    "fneu = Fneu[7]\n",
    "\n",
    "#Sandbox removal of peak regions and re-thresholding\n",
    "def synapse_freq_and_amp_extraction(f, fneu, frames):\n",
    "    \"\"\"Here we define our primary extraction function for suite2p F / Fneu.npy files; these files are unpacked iteratively \n",
    "    with the statement 'for f, fneu in zip(F, Fneu): followed by the outer function; this will unpack the parent fluorescence \n",
    "    files and gather freq / amplitude measures\"\"\"\n",
    "    fluoro_trace = f - 0.7*fneu\n",
    "    corrected_sample_trace = BaselineRemoval(fluoro_trace)\n",
    "    corrected_trace = corrected_sample_trace.ZhangFit()\n",
    "    def first_pass_peak_removal():\n",
    "        first_pass = np.copy(corrected_trace)\n",
    "        first_pass_peaks, _ = find_peaks(first_pass, height = 1.5*np.std(first_pass), distance = 5)\n",
    "        peak_regions = []\n",
    "        for peak in first_pass_peaks:\n",
    "            start = max(0, peak-frames)\n",
    "            end = min(len(first_pass)-1, peak+frames+1)\n",
    "        peak_regions += list(np.arange(start, end))\n",
    "        # for peak in first_pass_peaks:\n",
    "        #     peak_regions += list(np.arange(peak-frames, peak+frames+1))\n",
    "        first_pass[peak_regions]=0\n",
    "        threshold = 2.5*np.std(first_pass)\n",
    "        # plt.plot(corrected_trace)\n",
    "        return threshold\n",
    "    threshold = first_pass_peak_removal()\n",
    "    synapse_peaks, _ = find_peaks(corrected_trace, height = threshold, distance = 20)\n",
    "    plt.ylim(-10,400)\n",
    "    plt.plot(corrected_trace)\n",
    "    plt.plot(synapse_peaks, corrected_trace[synapse_peaks], \"x\")\n",
    "    plt.plot(np.full_like(corrected_trace, threshold), \"--\",color = \"grey\")\n",
    "    plt.plot(np.full_like(corrected_trace, np.median(corrected_trace)), \"--\", color = 'r')\n",
    "    plt.show()\n",
    "    \n",
    "for j, k in zip(F, Fneu):\n",
    "    synapse_freq_and_amp_extraction(j, k, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for peak in first_pass_peaks:\n",
    "    start = max(0, peak-frames)\n",
    "    end = min(len(first_pass)-1, peak+frames+1)\n",
    "    peak_regions += list(np.arange(start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, k in zip(F, Fneu):\n",
    "    synapse_freq_and_amp_extraction(j, k, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluoro_trace = f - 0.7*fneu\n",
    "corrected_sample_trace = BaselineRemoval(fluoro_trace)\n",
    "corrected_trace = corrected_sample_trace.ZhangFit()\n",
    "plt.plot(corrected_trace)\n",
    "plt.plot(np.full_like(corrected_trace, 10*np.std(trace)), '--', color = 'r')\n",
    "plt.plot(np.full_like(corrected_trace, (trace.max()-trace.min()+np.median(corrected_trace))), '-', color = 'grey')\n",
    "plt.plot(np.full_like(corrected_trace, (3*np.std(noise) + np.median(trace))), color = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = BaselineRemoval(fneu)\n",
    "noise = correction.ZhangFit(repitition=100)\n",
    "3*np.std(noise) + np.median(trace)\n",
    "plt.plot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(corrected_trace)\n",
    "plt.plot(trace)\n",
    "# plt.plot(trace, trace[peaks], \"x\")\n",
    "plt.plot(np.full_like(trace, 10*np.std(trace)), \"--\",color = \"grey\")\n",
    "plt.plot(np.full_like(trace, np.median(trace)), \"--\", color = 'r')\n",
    "print(np.std(trace))\n",
    "# np.std(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create a copy of a baseline corrected fluorescence trace and remove the peak regions (+/- the surrounding area) to compute baseline\"\"\"\n",
    "\n",
    "n = 40 # number of integers on either side\n",
    "indices = []\n",
    "for peak in peak_list:\n",
    "    indices += list(np.arange(peak-n, peak+n+1))\n",
    "trace[indices] = 0\n",
    "plt.plot(trace)\n",
    "\n",
    "\n",
    "# zero = np.copy(trace)\n",
    "# zero[peak_list] = 0\n",
    "# plt.plot(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace[indices] = 0\n",
    "plt.plot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Figure plotting\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
